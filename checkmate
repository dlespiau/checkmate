#!/usr/bin/env python3
# vim: set ts=8 sw=4 et cino=:0,t0,(0,u0,w1,m1:

import bisect
import optparse
import os
import re
import shlex
import shutil
import signal
import subprocess
import sys

#
# Return back to the directory the script was launched from on SIGINT
#

start_directory = os.getcwd()

def sigint_handler(signal, frame):
    os.chdir(start_directory)
    sys.exit(0)
signal.signal(signal.SIGINT, sigint_handler)

#
# Coloured messages
#

verbose = False
quiet = False
print_colors = { 'debug': 37, 'info': 32, 'warn': 33, 'error': 31 }

def _color_print(level, msg, stream = sys.stdout):
    if os.getenv('ANSI_COLORS_DISABLED') is None:
        color = print_colors[level]
        level = '\033[%dm%s:\033[0m' % (color, level)
    stream.write('%s %s\n' % (level, msg))

def debug(msg):
    if not verbose:
        return
    _color_print('debug', msg)

def info(msg):
    _color_print('info', msg)

def warn(msg):
    _color_print('warn', msg)

def error(msg):
    _color_print('error', msg)

#
# Helper to execute a command synchronously and get stdout/stderr
#

def execute(cmd, shell=False):
    if not shell:
        args = shlex.split(cmd)
    else:
        args = cmd

    debug("executing: " + cmd)
    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                         shell=shell)
    out, err = p.communicate()
    return out.decode('utf-8').strip(), p.returncode

def execute_to_file(cmd, filename, shell=False, append=False, env=None):
    if not shell:
        args = shlex.split(cmd)
    else:
        args = cmd

    if append:
        f = open(filename, 'a+')
    else:
        f = open(filename, 'w+')

    new_env = os.environ.copy()
    if env:
        new_env.update(env)

    debug("executing: " + cmd)
    p = subprocess.Popen(args, stdout=f, stderr=subprocess.STDOUT, shell=shell,
                         env=new_env)
    ret = p.wait()
    f.close()
    return ret

def able_to_run(cmd):
    out, ret = execute(cmd)
    return ret == 0

#
# Various helpers
#

def ensure_directories(dirs):
    for d in dirs:
        if not os.path.isdir(d):
            os.mkdir(d)

def exec_file(filename, global_vars, local_vars=None):
    with open(filename) as f:
        code = compile(f.read(), filename, 'exec')
        if not local_vars:
            local_vars = global_vars
        exec(code, global_vars, local_vars)

def normalize_path(path):
    return re.sub('[/]', '_', path)

def enum(*sequential, **named):
    enums = dict(zip(sequential, range(len(sequential))), **named)
    reverse = dict((value, key) for key, value in enums.items())
    enums['to_enum'] = reverse
    return type('Enum', (), enums)

def base_dir():
    return os.path.dirname(os.path.realpath(__file__))

#
# Exceptions
#

class Error(Exception):
	def __init__(self, msg):
		self.msg = msg

class ConfigError(Exception):
    pass

class NotFound(Error):
    pass

class GitError(Error):
    pass

class CollectError(Error):
    pass

class AnalyseError(Error):
    pass

class BuildError(Error):
    pass

#
# Represents a git commit
#

class GitCommit:
    def __init__(self, path, rev):
        self.base_path = path
        self.rev = rev
        self._short_hash = None
        self._timestamp = None
        self._subject = None

        self._hash, ret = execute('git rev-parse %s' % self.rev)
        if ret:
            raise GitError("Failed to parse revision '%s'" % self.rev)

        self._short_hash, ret = execute('git rev-parse --short %s' % self.rev)

        # only store abbrev if it exists and we're not in a detached state
        self._abbrev = None
        abbrev, ret = execute('git rev-parse --abbrev-ref %s' % self.rev)
        if abbrev and abbrev != 'HEAD':
            self._abbrev = abbrev

    def hash(self):
        return self._hash

    def short_hash(self):
        return self._short_hash

    def timestamp(self):
        if self._timestamp:
            return self._timestamp

        self._timestamp, ret = execute('git show -s --format=%%ct %s' %
                                       self._hash)
        if ret:
            raise GitError("Failed to get the commit timestamp of '%s'" %
                           self._hash)

        return self._timestamp

    def subject(self):
        if not self._subject:
            self._subject, ret = execute('git show -s --format=%%s %s' %
                                         self._hash)
        return self._subject

    def checkout(self):
        if self._abbrev:
            execute('git checkout %s' % self._abbrev)
        else:
            execute('git checkout %s' % self.hash())

#
# The on-disk database with all the already treated commits. This is just a
# file with one commit per line, ordered by commit date. Each line is:
#   hash;timestamp
#

DB = enum('HASH', 'COMMIT_TS')

class CommitDB:
    def __init__(self, path):
        self.base_path = path
        self.db_path = os.path.join(path, '.mate', 'db')
        ensure_directories(('.mate', ))

    def load(self):
        self.commits = []
        self.keys = []
        if not os.path.exists(self.db_path):
            return

        with open(self.db_path, 'r+') as f:
            for line in f:
                fields = line.split(':')
                fields[-1] = fields[-1].strip()
                self.commits.append(fields)

        # precompute the list of keys for bisect
        self.keys = [c[1] for c in self.commits]

    def save(self):
        with open(self.db_path + '~', 'w+') as f:
            for commit in self.commits:
                f.write("%s:%s\n" % (commit[DB.HASH], commit[DB.COMMIT_TS]))
        os.rename(self.db_path + '~', self.db_path)

    def is_known_commit(self, commit):
        i = bisect.bisect_left(self.keys, commit.timestamp())

        while i < len(self.keys) and \
                self.commits[i][DB.COMMIT_TS] == commit.timestamp():
            if self.commits[i][DB.HASH] == commit.hash():
                return True, i
            i += 1

        return False, -1

    def insert_commit(self, commit):
        i = bisect.bisect_left(self.keys, commit.timestamp())
        self.keys.insert(i, commit.timestamp())
        self.commits.insert(i, (commit.hash(), commit.timestamp()))

#
# An artefact is data collected from a git repository. For instance the output
# (stdout) of a build is the artefact used by the CompilationWarningMetric
#

class Artefact:
    need_file = False

    def __init__(self, project, args=None):
        self.project = project
        self.config = project.config
        self.commit = project.current_commit
        self.artefact_dir = project.hash_dirs['artefacts']
        self.args = args

        self._has_metadata = False

    def _name(self):
        return self.__class__.name

    def _info(self, msg):
        info('%s: %s: %s' % (self.commit.short_hash(), self._name(), msg))

    def _config__list(self, var):
        try:
            val = self.config.get_artefact(self._name())[var]
        except (KeyError, TypeError):
            val = []
        return val

    def _config(self, var):
        try:
            val = self.config.get_artefact(self._name())[var]
        except (KeyError, TypeError):
            val = None
        return val

    def _config__global(self, var):
        try:
            val = self.config.config[var]
        except (KeyError, TypeError):
            val = None
        return val

    def log_file(self, file_path=None):
        if file_path:
            return os.path.join(self.artefact_dir, self._name() + '-' +
                                normalize_path(file_path))
        else:
            return os.path.join(self.artefact_dir, self._name())

    def _do(self, command, shell=False):
        out, ret = execute(command, shell=shell)
        return ret == 0

    def _can_skip(self, file_path=None):
        f = self.log_file(file_path)
        return os.path.exists(f)

    def _artefact(self, command, file_path=None, shell=False):
        f = self.log_file(file_path)

        if file_path:
            file_str = " for file " + file_path
        else:
            file_str = ''

        if self._can_skip(file_path):
            self._info("Artefact '%s'%s already generated, skipping..." %
                       (self._name(), file_str))
            return 0
        else:
            self._info("Generating artefact '%s'%s" % (self._name(), file_str))

        env_vars = self._config__list('env')
        return execute_to_file(command, f,
                               shell=shell,
                               append=self._has_metadata,
                               env=env_vars)

    # FIXME, a few problems with that still... don't use
    def _metadata(self, key, val, name=None, file_path=None):
        if self._can_skip(file_path):
            return

        self._has_metadata = True
        f = self.log_file(file_path)
        with open(f, 'w+') as f:
            f.write("MATE_METADATA:%s:%s\n" % (key, val))

    def do_ensure_collect():
        pass

    # Make sure we can actually run collect. Subclasses can override
    # do_ensure_collect() to hook in there.
    def ensure_collect(self):
        self.do_ensure_collect()

    # @files is there for artefacts that act on files (eg. 'memcheck' needs a
    # program to run). It can be None.
    def collect(self, files):
        if self.__class__.need_file and not files:
            raise CollectError("The '%s' artefact needs files to operate on" %
                               self._name())

        self.ensure_collect()

        if files:
            for f in files:
                self.do_collect(f)
        else:
                self.do_collect()

class BuildArtefact(Artefact):
    name = 'build'

    def do_ensure_collect(self):
        if not os.path.isfile('Makefile'):
            raise CollectError("%s has no Makefile" % self.project.path)

    def do_collect(self, files=None):
        if not self._can_skip():
            self._do('make clean')
        self._artefact('make')

class KernelBuildArtefact(Artefact):
    name = 'linux-build'

    def do_ensure_collect(self):
        # Of course, this doesn't work with out of tree modules. Meh.
        if not self.project.is_linux_kernel():
            raise CollectError("%s is not a Linux kernel" % self.project.path)

    def do_collect(self, files=None):
        path = self._config__global('linux-path')
        if path:
            if not self._can_skip():
                self._do('make clean M=%s' % path)
            self._artefact('make M=%s' % path)
        else:
            if not self._can_skip():
                self._do('make clean')
            self._artefact('make')

class KernelSparseArtefact(Artefact):
    name = 'linux-sparse'

    def do_ensure_collect(self):
        if not able_to_run('sparse --version'):
            raise CollectError("sparse is not installed")

    def do_collect(self, files=None):
        path = self._config__global('linux-path')
        if path:
            self._artefact('make C=2 M=%s' % path)
        else:
            self._artefact('make C=2')

class KernelSmatchArtefact(Artefact):
    name = 'linux-smatch'

    def do_ensure_collect(self):
        if not able_to_run('smatch --version'):
            raise CollectError("smatch is not installed")

    def do_collect(self, files=None):
        path = self._config__global('linux-path')
        if path:
            self._artefact('make CHECK="smatch -p=kernel" C=2 M=%s' % path)
        else:
            self._artefact('make CHECK="smatch -p=kernel" C=2')

checkpatch_args = '--max-line-length=%(n_chars)s --no-summary %(extra-args)s'
invoke_checkpatch = 'git format-patch --stdout -1 %(hash)s  | \
./scripts/checkpatch.pl ' + checkpatch_args + ' -'
invoke_checkpatch_files = './scripts/checkpatch.pl ' + checkpatch_args+ \
                          ' -f %(files)s'

class KernelCheckpatchArtefact(Artefact):
    name = 'linux-checkpatch'

    def do_ensure_collect(self):
        # Of course, this doesn't work with out of tree modules. Meh.
        if not self.project.is_linux_kernel():
            raise CollectError("%s is not a Linux kernel" % self.project.path)

    def do_collect(self, files=None):
        n_chars = self._config__global('checkpatch-max-line-length') or 120
        files = self._config__global('checkpatch-files')
        extra_args = self._config__global('checkpatch-extra-args') or ''

        if files:
            self._artefact(invoke_checkpatch_files % {
                            'n_chars' : n_chars,
                            'extra-args': extra_args,
                            'files': files,
                           },
                           shell=True)
        else:
            self._artefact(invoke_checkpatch % {
                            'hash': self.commit.hash(),
                            'n_chars' : n_chars,
                            'extra-args': extra_args,
                           },
                           shell=True)

# We could also get the list of files from the config file
# self.
# self._artefact('./scripts/checkpatch.pl --max-line-length=120 -f drivers/gpu/drm/i915/*.c --terse --no-summary')

invoke_vg_libtool = './libtool --mode=execute valgrind --tool=memcheck \
--leak-check=full --leak-resolution=high --num-callers=20 --track-origins=yes'

class MemcheckArtefact(Artefact):
    name = 'memcheck'
    need_file = True

    def do_ensure_collect(self):
        if not able_to_run('valgrind --version'):
            raise CollectError("memcheck: valgrind is not installed")
        if not self.project.is_using_libtool():
            raise CollectError("memcheck: FIXME: not implemented")

    def do_collect(self, files=None):
        global invoke_vg_libtool
        #self._metadata('filename', file, file_path=file)
        for s in self._config__list('suppressions'):
            invoke_vg_libtool += " --suppressions=" + s
        self._artefact(invoke_vg_libtool + ' ' + file, file_path=file)

known_artefacts = (
        BuildArtefact,
        KernelBuildArtefact,
        KernelSparseArtefact,
        KernelSmatchArtefact,
        KernelCheckpatchArtefact,
        MemcheckArtefact,
)

#
# A metric is an object that collect data on an artefact
#

class Metric:
    def __init__(self, project, args=None):
        self.config = project.config
        self.commit = project.current_commit
        self.args = args

        self.value = 0

    def _name(self, override=None):
        if override:
            return override
        return self.__class__.name

    def _info(self, msg):
        info('%s: %s: %s' % (self.commit.short_hash(), self._name(), msg))

    def get_config_var(self, var):
        try:
            val = self.config.get_metric(self._name())[var]
        except (KeyError, TypeError):
            val = None
        return val

    def analyse(self, artefact, files):
        if files:
            for f in files:
                self.do_analyse(artefact, f)
        else:
                self.do_analyse(artefact)

    def output(self):
        self.do_output()


class CompilationErrorMetric(Metric):
    name = 'compilation-errors'
    artefacts = ['build', 'linux-build']

    def do_analyse(self, artefact, file=None):
        r = re.compile(':[0-9]+:[0-9]+: error:')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d errors' % self.value)

class CompilationWarningMetric(Metric):
    name = 'compilation-warnings'
    artefacts = ['build', 'linux-build']

    def do_analyse(self, artefact, file=None):
        r = re.compile(':[0-9]+:[0-9]+: warning:')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d warnings' % self.value)

class SparseWarningMetric(Metric):
    name = 'sparse-warnings'
    artefacts = ['linux-sparse']

    def do_analyse(self, artefact, file=None):
        r = re.compile(':[0-9]+:[0-9]+: warning:')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d warnings' % self.value)

class SparseErrorMetric(Metric):
    name = 'sparse-errors'
    artefacts = ['linux-sparse']

    def do_analyse(self, artefact, file=None):
        r = re.compile(':[0-9]+:[0-9]+: error:')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d errors' % self.value)

class SmatchWarningMetric(Metric):
    name = 'smatch-warnings'
    artefacts = ['linux-smatch']

    def do_analyse(self, artefact, file=None):
        r = re.compile('.[ch]:[0-9]+ ')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d warnings' % self.value)

class CheckpatchErrorMetric(Metric):
    name = 'checkpatch-errors'
    artefacts = ['linux-checkpatch']

    def do_analyse(self, artefact, file=None):
        r = re.compile('^ERROR: ')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d errors' % self.value)

class CheckpatchWarningMetric(Metric):
    name = 'checkpatch-warnings'
    artefacts = ['linux-checkpatch']

    def do_analyse(self, artefact, file=None):
        r = re.compile('^WARNING: ')
        with open(artefact.log_file(), 'r') as f:
            for line in f:
                if r.search(line):
                    self.value += 1

    def do_output(self):
        self._info('%d warnings' % self.value)

class MemcheckErrorMetric(Metric):
    name = 'memcheck-errors'
    description = "Number of errors reported by valgrind's memcheck tool"
    artefacts = ['memcheck']

    def do_analyse(self,  artefact, file_path):
        r = re.compile('ERROR SUMMARY: ([0-9]+) errors')
        with open(artefact.log_file(file_path), 'r') as f:
            for line in f:
                match = r.search(line)
                if match:
                    self.value = int(match.group(1))
                    return

        raise AnalyseError('memcheck: could not find the error summary')

    def do_output(self):
        self._info('%d errors' % self.value)

known_metrics = (
        CompilationErrorMetric,
        CompilationWarningMetric,
        SparseWarningMetric,
        SparseErrorMetric,
        SmatchWarningMetric,
        CheckpatchErrorMetric,
        CheckpatchWarningMetric,
        MemcheckErrorMetric,
)

#
# Config file support
#

class Config:
    file = {}

    def __init__(self, filename):
        try:
            exec_file(filename, Config.file)
            debug("Loading config file: %s" % filename)
        except IOError:
            warn("No config found, create a .mateconfig file for this project")
        except Exception as detail:
            raise ConfigError(detail)

    def __getattr__(self, name):
        if name in Config.file:
            return Config.file[name]
        elif name == 'artefacts':
            return {}

        raise AttributeError("%r object has no attribute %r" %
                                         (type(self).__name__, name))

    def get_metric(self, name):
        for m in self.metrics:
            if m['name'] == name:
                return m
        return None

    def get_artefact(self, name):
        if self.artefacts and name in self.artefacts:
            return self.artefacts[name]
        return None

#
# HTML support
#

import jinja2 as jinja

def D(*args):
    return ('d', os.path.join(*args))

def F(*args):
    return ('f', os.path.join(*args))

class HTMLOutput:
    assets = (
        D('css'),
        D('js'),
        F('css', 'bootstrap.min.css'),
        F('js',  'bootstrap.min.js'),
        F('js',  'jquery-1.10.2.min.js'),
        F('js',  'd3.v3.min.js'),
        F('js',  'simple-graph.js'),
    )

    def __init__(self, path):
        self.path = path
        if not os.path.isdir(path):
            os.makedirs(path)

        loader = jinja.FileSystemLoader(os.path.join(base_dir(), 'html'))
        self.env = jinja.Environment(loader=loader,
                                     trim_blocks=True,
                                     # needs jinja 2.7
                                     # lstrip_blocks=True,
                                     )

    def _ensure_assets(self):
        for asset in self.__class__.assets:
            type = asset[0]
            path = asset[1]
            if type == 'd':
                try:
                    os.makedirs(path)
                except FileExistsError:
                    pass
            else:
                relative = os.path.dirname(path)
                shutil.copy(os.path.join(base_dir(), 'html', path),
                            os.path.join(self.path, relative))

    def render(self, project):
        self._ensure_assets()

        template = self.env.get_template('report.html')
        res = template.render({ 'project': project, })
        with open("report.html", "wb") as output:
                output.write(bytes(res, 'utf-8'))

#
# Represents the software project we want to gather metrics on
#

class Project:
    def __init__(self, path):
        self.path = path
        self.db = CommitDB(path)
        self.db.load()
        self.hash_dirs = {}

        self.name = os.path.basename(os.path.abspath(path))

        self.init()

    def init(self):
        try:
            os.chdir(self.path)
        except FileNotFoundError:
            raise NotFound("%s not a directory" % self.path)

        self.config = Config('.mateconfig')

        if not os.path.isdir('.git'):
            raise GitError("%s is not a git repository" % self.path)

        self.start_commit = GitCommit(self.path, 'HEAD')

    def setup_hash_dir(self, name):
        git_sha = self.current_commit.hash()
        hash_dir = os.path.join('.mate', name)
        short_dir = os.path.join(hash_dir, git_sha[:2])
        long_dir = os.path.join(short_dir, git_sha[2:])
        self.hash_dirs[name] = long_dir
        ensure_directories((hash_dir, short_dir, long_dir))

    def setup(self, rev='HEAD'):
        if rev == 'HEAD':
            self.current_commit = self.start_commit
        else:
            self.current_commit = GitCommit(self.path, rev)

        ensure_directories(('.mate', ))
        self.setup_hash_dir('artefacts')
        self.setup_hash_dir('metrics')

        info("Checking %s" % self.current_commit.subject())

        # checkout the commit we want to inspect
        self.current_commit.checkout()

    def fini(self):
        global start_directory

        self.start_commit.checkout()
        os.chdir(start_directory)

    def _debug(self, msg):
        debug('%s: %s' % (self.current_commit.short_hash(), msg))

    def _info(self, msg):
        info('%s: %s' % (self.current_commit.short_hash(), msg))

    def _done(self):
        (found, index) = self.db.is_known_commit(self.current_commit)
        if found:
            return

        self.db.insert_commit(self.current_commit)
        self.db.save()

    def is_using_libtool(self):
        return os.path.exists('libtool')

    def is_linux_kernel(self):
        return os.path.exists(os.path.join('Documentation',
                                           'kernel-parameters.txt'))

    def clean(self):
        for d in ('artefacts', 'metrics'):
            debug('Removing %s' % self.hash_dirs[d])
            shutil.rmtree(self.hash_dirs[d])

    def _find_metric(self, name):
        for cls in known_metrics:
            if cls.name == name:
                return cls(self)
        raise ConfigError("'%s' is not a valid metric name" % name)

    def _find_artefact(self, metric, conf):
        artefact = metric.artefacts[0]
        if 'artefact' in conf and conf['artefact'] in metric.artefacts:
            artefact = conf['artefact']

        for cls in known_artefacts:
            if cls.name == artefact:
                return cls(self)
        raise CollectError("'%s' has no associated artefact (%s)" %
                           (metric.name, artefact))


    def collect_artefacts(self):
        try:
            metrics = self.config.metrics
        except AttributeError:
            warn("No metrics configured")
            sys.exit(0)

        for conf in metrics:
            try:
                metric = self._find_metric(conf['name'])
            except KeyError:
                raise ConfigError("Configuration file has an unnamed metric")

            artefact = self._find_artefact(metric, conf)

            self._info("Collecting artefact '%s' for metric '%s'" %
                       (artefact.name, metric.name))

            files = metric.get_config_var('files')
            artefact.collect(files)

        self._done()

    def analyse(self):
        # start by making sure we have the necessary artefacts
        self.collect_artefacts()

        for conf in self.config.metrics:
            try:
                metric = self._find_metric(conf['name'])
            except KeyError:
                raise ConfigError("Configuration file has an unnamed metric")

            artefact = self._find_artefact(metric, conf)
            files = metric.get_config_var('files')
            metric.analyse(artefact, files)
            metric.output()

    def report(self, directory='.', format='html'):
        out = HTMLOutput(directory)
        out.render(self)

#
# Main
#

usage = """Usage: mate [options] command"

List of commands:
    help                        display this help
    clean [commit]              remove generated data (default to HEAD)
    collect [commit]            collect artefacts for commit (default to HEAD)
    analyse [commit]            analyse commit (default to HEAD)"""

parser = optparse.OptionParser(usage, version=1.0)

def parse_options(args):
    global parser

    parser.add_option("-v", "--verbose", action="store_true",
            dest="verbose", default=False,
            help="be more verbose")

    parser.add_option("-C", "", action="store", dest="directory",
            default='.', help="change to directory")

    (options, args) = parser.parse_args()

    return (options, args)

def usage():
    parser.print_help()
    sys.exit(1)

class Mate:
    def __init__(self):
        pass

    def _is_known_command(self, cmd):
        try:
            fn = getattr(self, cmd)
            return fn and fn not in ('dispatch', )
        except:
            pass

    def help(self, args):
        usage()

    def _project_do(self, method, args):
        project = Project(options.directory)

        rev_list = ['HEAD']
        if len(args) > 0:
            refspec = args[0]

        if '..' in refspec:
            # not perfect but suit my usage
            output, ret = execute('git rev-list %s' % refspec)
            if ret:
                raise GitError("%s is not a valid refspec" % refspec)

            rev_list = []
            for rev in output.split('\n'):
                rev_list.append(rev)
        else:
            rev_list[0] = refspec

        try:
            for rev in reversed(rev_list):
                project.setup(rev)
                getattr(project, method)()
        except Error as e:
            error(e.msg)
            sys.exit(1)
        finally:
            project.fini()

    def clean(self, args):
        self._project_do('clean', args)

    def collect(self, args):
        self._project_do('collect_artefacts', args)

    def analyse(self, args):
        self._project_do('analyse', args)

    def report(self, args):
        self._project_do('report', args)

    def dispatch(self, cmd, args):
        if not mate._is_known_command(cmd):
            error("Unknown command '%s'" % cmd)
            sys.exit(1)

        method = getattr(self, cmd)
        method(args)


if __name__ == '__main__':
    (options, args) = parse_options(sys.argv[1:])
    verbose = options.verbose

    if len(args) == 0:
        usage()

    mate = Mate()
    mate.dispatch(args[0], args[1:])
